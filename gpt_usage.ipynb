{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================\n",
    "# 0. Paths & Globals\n",
    "# ============================================\n",
    "\n",
    "# 프로젝트 경로 설정 (실제 경로에 맞게 수정 필요)\n",
    "ROOT = \"/content/drive/MyDrive/project_release\"\n",
    "DATA_BASE = f\"{ROOT}/Amazon_products\"\n",
    "\n",
    "TRAIN_CORPUS = f\"{DATA_BASE}/train/train_corpus.txt\"\n",
    "CLASS_PATH   = f\"{DATA_BASE}/classes.txt\"\n",
    "\n",
    "# 생성된 Strong Silver Label이 저장될 경로\n",
    "# 3k 샘플을 위해 'train_strong_silver_labels_3k.csv'로 변경을 고려할 수 있습니다.\n",
    "# 여기서는 2k 샘플을 3개씩 처리하는 것으로 가정하고 경로를 유지합니다.\n",
    "STRONG_SILVER_PATH = \"/content/train_strong_silver_labels_2k_s3.csv\" # 파일명 변경으로 3 samples/call임을 명시\n",
    "\n",
    "# LLM 설정\n",
    "try:\n",
    "    # 환경 변수에서 API 키를 가져오도록 수정하지 않고,\n",
    "    # 실제 환경에서 설정된 client를 사용한다고 가정합니다.\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    GPT_MODEL = \"gpt-4o-mini\" # 모델명은 환경에 따라 변경 가능\n",
    "    if not OPENAI_API_KEY:\n",
    "        client = None\n",
    "        print(\"[경고] OPENAI_API_KEY 환경 변수가 설정되지 않아 API 호출이 작동하지 않습니다.\")\n",
    "except Exception:\n",
    "    client = None\n",
    "\n",
    "# ============================================\n",
    "# 1. Loaders (기존과 동일)\n",
    "# ============================================\n",
    "\n",
    "def load_class_names(path):\n",
    "    \"\"\" 클래스 이름과 ID 매핑을 로드합니다. \"\"\"\n",
    "    name2id = {}\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: Class file not found at {path}\")\n",
    "        return name2id\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                cid = parts[0]\n",
    "                cname = \" \".join(parts[1:])\n",
    "                name2id[cname] = int(cid)\n",
    "    return name2id\n",
    "\n",
    "def load_corpus(path):\n",
    "    \"\"\" 코퍼스 전체를 로드합니다. (pid -> text) \"\"\"\n",
    "    pid2text = {}\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: Corpus file not found at {path}\")\n",
    "        return pid2text\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        # tqdm 대신 빠른 줄 수 세기\n",
    "        num_lines = sum(1 for _ in open(path, \"r\", encoding=\"utf-8\"))\n",
    "        f.seek(0)\n",
    "        for line in tqdm(f, total=num_lines, desc=\"Loading Train Corpus\"):\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                pid, txt = parts\n",
    "                pid2text[pid] = txt\n",
    "    return pid2text\n",
    "\n",
    "# ============================================\n",
    "# 2. LLM API 호출 및 라벨 생성 함수 (samples_per_call = 3으로 실행되도록 메인 블록 수정)\n",
    "# ============================================\n",
    "\n",
    "def generate_strong_labels_gpt(\n",
    "    pid2text, name2id, max_samples=2000, max_labels_per_doc=3, samples_per_call=3\n",
    "):\n",
    "    \"\"\"\n",
    "    GPT API를 호출하여 Strong Silver Label을 생성하고 결과를 반환합니다.\n",
    "    samples_per_call 만큼의 문서를 1 콜에 처리합니다.\n",
    "\n",
    "    :param max_samples: 총 라벨링할 문서의 수\n",
    "    :param samples_per_call: 1번의 API 호출로 처리할 문서의 수 (요청에 따라 3으로 설정됨)\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        print(\"[ERROR] GPT 클라이언트가 유효하지 않습니다. 라벨 생성을 건너뜁니다.\")\n",
    "        return {}\n",
    "\n",
    "    all_pids = list(pid2text.keys())\n",
    "    random.seed(42)\n",
    "    random.shuffle(all_pids)\n",
    "\n",
    "    # 처리할 PID 리스트 (2000개)\n",
    "    sample_pids = all_pids[:min(max_samples, len(all_pids))]\n",
    "    num_classes = max(name2id.values()) + 1 if name2id else 1\n",
    "\n",
    "    id_to_name = {v: k for k, v in name2id.items()}\n",
    "    class_names = {str(k): v for k, v in id_to_name.items()}\n",
    "\n",
    "    llm_labels = {}\n",
    "\n",
    "    # 프롬프트 정의\n",
    "    SYSTEM_PROMPT = (\n",
    "        \"You are an Amazon product classification expert. Your task is to assign the top 3 most relevant \"\n",
    "        \"class IDs to the provided product reviews. \"\n",
    "        \"The class IDs and names are: \" + json.dumps(class_names) + \". \"\n",
    "        f\"Respond ONLY with a single JSON object. The keys must be the product PIDs, and the values must be a list of \"\n",
    "        f\"the predicted class IDs (integers, maximum {max_labels_per_doc}). \"\n",
    "        \"Example: {\\\"pid_12345\\\": [101, 5, 20], \\\"pid_67890\\\": [40, 5, 12]}\"\n",
    "    )\n",
    "\n",
    "    # 샘플을 samples_per_call 개씩 그룹화\n",
    "    pid_groups = [\n",
    "        sample_pids[i:i + samples_per_call]\n",
    "        for i in range(0, len(sample_pids), samples_per_call)\n",
    "    ]\n",
    "\n",
    "    for group_pids in tqdm(pid_groups, desc=f\"Calling GPT ({samples_per_call} samples/call) for {len(sample_pids)} documents\"):\n",
    "\n",
    "        prompt_data = {pid: pid2text[pid] for pid in group_pids}\n",
    "        USER_PROMPT = \"Classify the following product descriptions: \\n\" + json.dumps(prompt_data)\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=GPT_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "                ],\n",
    "                #temperature=0.0\n",
    "            )\n",
    "\n",
    "            content = response.choices[0].message.content.strip()\n",
    "\n",
    "            try:\n",
    "                predicted_labels_batch = json.loads(content)\n",
    "                # 그룹 내의 모든 PID에 대해 결과 처리\n",
    "                for pid in group_pids:\n",
    "                    if pid in predicted_labels_batch and isinstance(predicted_labels_batch[pid], list):\n",
    "                        raw_labels = predicted_labels_batch[pid]\n",
    "                        # 정수로 변환 가능하고, 클래스 범위 내에 있는 유효한 라벨만 필터링\n",
    "                        valid_labels = [\n",
    "                            int(l) for l in raw_labels\n",
    "                            if (isinstance(l, (int, str)) and str(l).isdigit() and 0 <= int(l) < num_classes)\n",
    "                        ]\n",
    "                        # 상위 max_labels_per_doc 개만 유지\n",
    "                        llm_labels[pid] = valid_labels[:max_labels_per_doc] if valid_labels else [0]\n",
    "                    else:\n",
    "                        # 응답 JSON에 특정 PID가 없거나 형식이 잘못된 경우\n",
    "                        llm_labels[pid] = [0]\n",
    "                        # print(f\"\\n[Warning] PID {pid}에 대한 라벨을 찾을 수 없거나 형식이 잘못되었습니다.\")\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # JSON 파싱 실패 시 그룹 내 모든 PID를 라벨 0으로 처리\n",
    "                for pid in group_pids:\n",
    "                    llm_labels[pid] = [0]\n",
    "                # print(f\"\\n[Warning] JSON 파싱 오류. Raw response: {content[:50]}...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # API 호출 자체 실패 시 그룹 내 모든 PID를 라벨 0으로 처리\n",
    "            print(f\"\\n[Error] API 호출 실패: {e}\")\n",
    "            for pid in group_pids:\n",
    "                llm_labels[pid] = [0]\n",
    "            time.sleep(3) # API 제한을 피하기 위해 잠시 대기\n",
    "\n",
    "    return llm_labels\n",
    "\n",
    "# ============================================\n",
    "# 3. Main Execution Block for Cell 1 (수정된 파라미터)\n",
    "# ============================================\n",
    "\n",
    "print(\"=== CELL 1: GPT Strong Silver Label Generation ===\")\n",
    "\n",
    "# 1. 데이터 로드\n",
    "name2id = load_class_names(CLASS_PATH)\n",
    "pid2text = load_corpus(TRAIN_CORPUS)\n",
    "\n",
    "# 2. GPT 라벨링 실행\n",
    "# max_samples=2000: 총 2000개의 문서를 라벨링\n",
    "# max_labels_per_doc=3: 문서당 최대 3개의 라벨\n",
    "# samples_per_call=3: 1번의 API 호출당 3개의 문서 처리 (총 호출 횟수: 2000 / 3 약 667회)\n",
    "strong_labels_map = generate_strong_labels_gpt(\n",
    "    pid2text, name2id, max_samples=2000, max_labels_per_doc=3, samples_per_call=3\n",
    ")\n",
    "\n",
    "# 3. CSV 파일로 저장\n",
    "print(f\"\\n[Save] Saving Strong Silver Labels to {STRONG_SILVER_PATH}...\")\n",
    "with open(STRONG_SILVER_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"pid\", \"labels\"])\n",
    "    for pid, labs in tqdm(strong_labels_map.items(), desc=\"Writing CSV\"):\n",
    "        w.writerow([pid, \",\".join(map(str, labs))])\n",
    "\n",
    "print(f\"\\n✅ Cell 1 완료. Strong Silver Labels ({len(strong_labels_map)}개) 저장 완료. (파일: {STRONG_SILVER_PATH})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "###description\n",
    "# ============================================\n",
    "# 0. Paths & Globals\n",
    "# ============================================\n",
    "\n",
    "# 프로젝트 경로 설정 (실제 경로에 맞게 수정 필요)\n",
    "ROOT = \"/content/drive/MyDrive/project_release\"\n",
    "DATA_BASE = f\"{ROOT}/Amazon_products\"\n",
    "\n",
    "CLASS_PATH   = f\"{DATA_BASE}/classes.txt\"\n",
    "\n",
    "# 생성된 클래스 설명이 저장될 경로 (새로운 경로)\n",
    "CLASS_DESCRIPTION_PATH = \"/content/gpt_class_descriptions_100calls.json\"\n",
    "\n",
    "# LLM 설정\n",
    "try:\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    GPT_MODEL = \"gpt-4o-mini\"\n",
    "    if not OPENAI_API_KEY:\n",
    "        client = None\n",
    "        print(\"[경고] OPENAI_API_KEY 환경 변수가 설정되지 않아 API 호출이 작동하지 않습니다.\")\n",
    "except Exception:\n",
    "    client = None\n",
    "\n",
    "# LLM 호출 제한 설정\n",
    "MAX_CALLS = 100\n",
    "CLASSES_PER_CALL = 6 # 1회 호출당 처리할 클래스 수 (531 클래스를 100회 내에 처리하기 위해)\n",
    "\n",
    "# ============================================\n",
    "# 1. Loaders (기존과 동일)\n",
    "# ============================================\n",
    "\n",
    "def load_class_names(path):\n",
    "    \"\"\" 클래스 이름과 ID 매핑을 로드합니다. (ID -> Name 반환) \"\"\"\n",
    "    id_to_name = {}\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: Class file not found at {path}\")\n",
    "        return id_to_name\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                cid = parts[0]\n",
    "                cname = \" \".join(parts[1:])\n",
    "                # ID (정수) -> Name (문자열)으로 저장\n",
    "                id_to_name[int(cid)] = cname\n",
    "    return id_to_name\n",
    "\n",
    "# 코퍼스 로딩 함수는 이 태스크에서는 필요 없으므로 제거했습니다.\n",
    "\n",
    "# ============================================\n",
    "# 2. LLM API 호출 및 클래스 설명 생성 함수\n",
    "# ============================================\n",
    "\n",
    "def generate_class_descriptions_gpt(id_to_name, classes_per_call):\n",
    "    \"\"\"\n",
    "    GPT API를 호출하여 클래스 설명을 생성합니다.\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        print(\"[ERROR] GPT 클라이언트가 유효하지 않습니다. 설명 생성을 건너뜁니다.\")\n",
    "        return {}\n",
    "\n",
    "    all_cids = sorted(id_to_name.keys())\n",
    "    num_classes = len(all_cids)\n",
    "\n",
    "    # 100회 호출 제한을 위해 실제 호출할 그룹만 계산\n",
    "    num_calls_needed = (num_classes + classes_per_call - 1) // classes_per_call\n",
    "    num_calls_to_make = min(num_calls_needed, MAX_CALLS)\n",
    "\n",
    "    print(f\"[INFO] 총 클래스 수: {num_classes}. 호출당 클래스: {classes_per_call}. 예상 호출 횟수: {num_calls_to_make}회.\")\n",
    "\n",
    "    # 처리할 클래스 ID 리스트\n",
    "    sample_cids = all_cids\n",
    "\n",
    "    # 생성된 설명을 저장할 딕셔너리\n",
    "    generated_descriptions = {}\n",
    "\n",
    "    # 프롬프트 정의\n",
    "    SYSTEM_PROMPT = (\n",
    "        \"You are an expert in product taxonomy. Your task is to provide a concise, distinct, and objective definition \"\n",
    "        \"or description (under 15 words) for each class ID provided. The description should highlight the core purpose or characteristics \"\n",
    "        \"of the product category, making it easily distinguishable from others in the Amazon product hierarchy. \"\n",
    "        \"Respond ONLY with a single JSON object. The keys must be the class IDs (integers), and the values must be the generated description string. \"\n",
    "        \"Example: {\\\"101\\\": \\\"Small, handheld electronic devices for timekeeping.\\\", \\\"5\\\": \\\"Sweetened carbonated water, often flavored and colored.\\\"}\"\n",
    "    )\n",
    "\n",
    "    # 샘플을 classes_per_call 개씩 그룹화\n",
    "    cid_groups = [\n",
    "        sample_cids[i:i + classes_per_call]\n",
    "        for i in range(0, len(sample_cids), classes_per_call)\n",
    "    ][:num_calls_to_make] # 최대 100회 호출까지만 사용\n",
    "\n",
    "    for group_cids in tqdm(cid_groups, desc=f\"Calling GPT ({classes_per_call} classes/call)\"):\n",
    "\n",
    "        # 그룹 내 클래스 ID와 이름 준비\n",
    "        prompt_data = {\n",
    "            cid: id_to_name[cid]\n",
    "            for cid in group_cids\n",
    "        }\n",
    "\n",
    "        USER_PROMPT = \"Generate descriptions for the following classes (ID: Class Name): \\n\" + json.dumps(prompt_data)\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=GPT_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "                ],\n",
    "                temperature=0.0 # 객관적인 정의를 위해 낮은 온도 사용\n",
    "            )\n",
    "\n",
    "            content = response.choices[0].message.content.strip()\n",
    "\n",
    "            try:\n",
    "                # 응답 JSON 파싱\n",
    "                predicted_descriptions = json.loads(content)\n",
    "\n",
    "                for cid in group_cids:\n",
    "                    cid_str = str(cid)\n",
    "                    if cid_str in predicted_descriptions and isinstance(predicted_descriptions[cid_str], str):\n",
    "                        # 생성된 설명을 저장\n",
    "                        generated_descriptions[cid] = predicted_descriptions[cid_str]\n",
    "                    else:\n",
    "                        # 응답 JSON에 특정 CID가 없거나 형식이 잘못된 경우, 클래스 이름으로 대체\n",
    "                        generated_descriptions[cid] = id_to_name[cid]\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # JSON 파싱 실패 시, 그룹 내 모든 클래스는 클래스 이름으로 대체\n",
    "                for cid in group_cids:\n",
    "                    generated_descriptions[cid] = id_to_name[cid]\n",
    "                # print(f\"\\n[Warning] JSON 파싱 오류. Raw response: {content[:50]}...\")\n",
    "\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            # API 호출 자체 실패 시, 그룹 내 모든 클래스는 클래스 이름으로 대체\n",
    "            print(f\"\\n[Error] API 호출 실패: {e}. 클래스 ID {group_cids[0]}부터 대체.\")\n",
    "            for cid in group_cids:\n",
    "                generated_descriptions[cid] = id_to_name[cid]\n",
    "            time.sleep(3)\n",
    "\n",
    "    return generated_descriptions\n",
    "\n",
    "# ============================================\n",
    "# 3. Main Execution Block\n",
    "# ============================================\n",
    "\n",
    "print(\"=== CELL 1: GPT Class Description Generation (100 Call Limit) ===\")\n",
    "\n",
    "# 1. 데이터 로드 (ID -> Name 매핑)\n",
    "id_to_name = load_class_names(CLASS_PATH)\n",
    "\n",
    "# 2. GPT 설명 생성 실행\n",
    "generated_descriptions_map = generate_class_descriptions_gpt(\n",
    "    id_to_name,\n",
    "    classes_per_call=CLASSES_PER_CALL\n",
    ")\n",
    "\n",
    "# 3. JSON 파일로 저장\n",
    "print(f\"\\n[Save] Saving Class Descriptions to {CLASS_DESCRIPTION_PATH}...\")\n",
    "\n",
    "# {ID (int): Description (str)} 형태로 저장\n",
    "with open(CLASS_DESCRIPTION_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(generated_descriptions_map, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# 누락된 클래스 확인\n",
    "num_total = len(id_to_name)\n",
    "num_generated = len(generated_descriptions_map)\n",
    "num_missing = num_total - num_generated\n",
    "\n",
    "print(f\"\\n✅ Cell 1 완료. 총 클래스 수: {num_total}, 설명 생성 클래스 수: {num_generated}, 누락 수: {num_missing}\")\n",
    "print(f\"(파일: {CLASS_DESCRIPTION_PATH})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
